# ğŸš€ RMSA Live Demo - Deep Reinforcement Learning para Redes Ã“pticas

Demo visual espectacular comparando agentes de IA (Default vs Optimizado) resolviendo el problema **RMSA** (Routing, Modulation and Spectrum Assignment) en redes Ã³pticas WDM elÃ¡sticas.

---

## ğŸ“‹ DescripciÃ³n

AplicaciÃ³n de demostraciÃ³n que muestra **dramÃ¡ticamente** la diferencia entre:

- **ğŸ”µ AGENTE DEFAULT**: ConfiguraciÃ³n bÃ¡sica con reward binaria simple
- **ğŸŸ¢ AGENTE OPTIMIZADO**: HiperparÃ¡metros cientÃ­ficamente optimizados con reward multi-objetivo

### CaracterÃ­sticas Destacadas

âœ¨ **Interfaz Rich Terminal** - Dashboard en tiempo real visualmente impactante  
âš¡ **Procesamiento Paralelo** - Ambos agentes procesan las mismas peticiones simultÃ¡neamente  
ğŸ“Š **MÃ©tricas en Vivo** - Blocking probability, utilizaciÃ³n espectral, fragmentaciÃ³n, QoT  
ğŸ¯ **Fairness Garantizado** - Misma semilla para ambos agentes (comparaciÃ³n justa)  
ğŸ”¬ **CientÃ­ficamente Riguroso** - Basado en papers de DeepRMSA y MFDRL-RSA

---

## ğŸ–¥ï¸ Hardware Soportado

**PC de Desarrollo:**
- **CPU**: Ryzen 7 5700X3D (8 cores)
- **RAM**: 16 GB
- **GPU**: AMD Radeon RX 6700XT (12GB) - *Nota: En Windows, PyTorch usa CPU*

**Sistema Operativo**: Windows 11  
**Python**: 3.12.3

---

## ğŸ“¦ InstalaciÃ³n

### 1. Verificar Pre-requisitos

```powershell
python --version  # Debe ser Python 3.11+
```

### 2. Actualizar pip

```powershell
python -m pip install --upgrade pip setuptools wheel
```

### 3. Instalar PyTorch

**IMPORTANTE**: En Windows con GPU AMD, PyTorch usa CPU (ROCm solo en Linux).

```powershell
python -m pip install --user torch==2.5.1+cpu torchvision==0.20.1+cpu --index-url https://download.pytorch.org/whl/cpu
```

### 4. Instalar Dependencias del Proyecto

```powershell
cd c:\Users\Cris\Desktop\Taller3\rmsa_demo_live
python -m pip install --user -r requirements.txt
```

### 5. Verificar InstalaciÃ³n

```powershell
python -c "import torch, gymnasium, stable_baselines3, rich, rmsa_environment; print('âœ“ Todo instalado correctamente')"
```

---

## ğŸ—ï¸ Arquitectura del Sistema

```
rmsa_demo_live/
â”œâ”€â”€ config.py              # Configuraciones agentes (default vs optimizado)
â”œâ”€â”€ rmsa_environment.py    # ImplementaciÃ³n ambiente RMSA con NSFNET
â”œâ”€â”€ environment.py         # Wrappers y helpers de Gymnasium
â”œâ”€â”€ reward_functions.py    # Rewards: binaria vs multi-objetivo
â”œâ”€â”€ agents.py              # Builders PPO con dropout y arquitecturas custom
â”œâ”€â”€ metrics.py             # Tracking de mÃ©tricas en tiempo real
â”œâ”€â”€ visualizer.py          # Dashboard Rich con layout dividido
â”œâ”€â”€ trainer.py             # Entrenamiento automatizado
â”œâ”€â”€ demo.py                # â­ Script principal de demo
â”œâ”€â”€ requirements.txt       # Dependencias Python
â””â”€â”€ README.md              # Esta documentaciÃ³n
```

---

## ğŸ® Uso

### Entrenar Agentes

**Entrenar solo agente default** (mÃ¡s rÃ¡pido):
```powershell
python trainer.py --default
```

**Entrenar solo agente optimizado** (mejor rendimiento):
```powershell
python trainer.py --optimized
```

**Entrenar ambos** (recomendado para demo completa):
```powershell
python trainer.py --default --optimized
```

**Tiempos estimados de entrenamiento (CPU Ryzen 7 5700X3D):**
- Agente Default (30k steps): ~6-10 minutos
- Agente Optimizado (60k steps): ~15-25 minutos

### Ejecutar Demo en Vivo

```powershell
python demo.py
```

La demo procesarÃ¡ **200 peticiones de conexiÃ³n** mostrando mÃ©tricas en tiempo real comparando ambos agentes lado a lado.

**DuraciÃ³n**: ~3-5 minutos  
**Efecto Visual**: Â¡ESPECTACULAR! ğŸ†

---

## ğŸ§  Configuraciones de los Agentes

### ğŸ”µ Agente DEFAULT

```python
Arquitectura: 2 capas Ã— 128 neuronas
Learning Rate: 1e-3 (convergencia rÃ¡pida pero subÃ³ptima)
ActivaciÃ³n: ReLU
Reward: Binaria simple (+1 Ã©xito, -1 bloqueo)
Gamma: 0.99
Batch Size: 64
Dropout: 0.0
```

### ğŸŸ¢ Agente OPTIMIZADO

```python
Arquitectura: 4 capas Ã— 256 neuronas
Learning Rate: 2.7e-4 (optimizado cientÃ­ficamente)
ActivaciÃ³n: SiLU/Swish (mejor para redes Ã³pticas)
Reward: Multi-objetivo (5 componentes)
  - Ã‰xito asignaciÃ³n: Â±10.0
  - Quality of Transmission: -exp(-OSNR/20.0) Ã— 3.0
  - Eficiencia espectral: 5.0 Ã— (1.0 - utilizaciÃ³n)
  - FragmentaciÃ³n: -2.0 Ã— Ã­ndice_fragmentaciÃ³n
  - Balance de carga: 1.5 Ã— factor_balance
Gamma: 0.997 (mayor consideraciÃ³n futuro)
Batch Size: 256
Dropout: 0.2
Gradient Clipping: 0.8
```

---

## ğŸ“Š MÃ©tricas Monitoreadas

La demo muestra en tiempo real:

| MÃ©trica | DescripciÃ³n |
|---------|-------------|
| **Blocking Probability** | % de conexiones bloqueadas (objetivo: <5%) |
| **Acceptance Rate** | % de conexiones exitosas |
| **Spectral Utilization** | Uso del espectro Ã³ptico |
| **Fragmentation Index** | Nivel de fragmentaciÃ³n espectral |
| **QoT Compliance** | Calidad de transmisiÃ³n Ã³ptica |
| **Load Balance** | Balance de carga entre enlaces |
| **Reward Acumulado** | Suma de rewards por episodio |

---

## ğŸŒ Ambiente RMSA

### TopologÃ­a: NSFNET
- **Nodos**: 14
- **Enlaces**: 21
- **Distancias**: Realistas (300-2700 km)

### Espectro Ã“ptico
- **Banda**: C-band
- **Frequency Slots**: 196
- **Granularidad**: 12.5 GHz

### Formatos de ModulaciÃ³n

| Formato | Alcance | Eficiencia Espectral |
|---------|---------|---------------------|
| BPSK | 4000 km | 1 bit/s/Hz |
| QPSK | 2000 km | 2 bit/s/Hz |
| 8QAM | 1000 km | 3 bit/s/Hz |
| 16QAM | 500 km | 4 bit/s/Hz |

### TrÃ¡fico
- **Bit Rates**: 25, 50, 100, 200, 400 Gbps
- **DistribuciÃ³n**: Exponencial (load factor = 0.8)
- **PolÃ­tica**: First-Fit spectrum assignment
- **Rutas**: K=3 shortest paths

---

## ğŸ¯ Criterios de Ã‰xito

La demo es exitosa si:

âœ… **Agente Optimizado** muestra blocking <5% vs >12% del default  
âœ… **Diferencias visuales** son dramÃ¡ticas e inmediatas  
âœ… **Demo corre** sin interrupciones en 3-5 minutos  
âœ… **MÃ©tricas** se actualizan suavemente en tiempo real  
âœ… **Interfaz Rich** es profesional y espectacular  
âœ… **Audiencia** reconoce inmediatamente quÃ© agente es superior

---

## ğŸ”§ Troubleshooting

### Error: "optical-rl-gym not found"
**SoluciÃ³n**: Usamos implementaciÃ³n custom en `rmsa_environment.py`. No se requiere optical-rl-gym.

### Error: "GPU not detected"
**SoluciÃ³n**: Normal en Windows con AMD. PyTorch usa CPU que es completamente funcional.

### Entrenamiento muy lento
**SoluciÃ³n**: 
- Reducir `timesteps` en `config.py`
- Usar `--default` solo para pruebas rÃ¡pidas
- Batch size ya optimizado para tu CPU

### Demo se congela
**SoluciÃ³n**:
- Verificar modelos entrenados existen en `models/`
- Reducir `demo_requests` en `config.py`
- Cerrar otras aplicaciones pesadas

---

## ğŸ“š Referencias CientÃ­ficas

1. **DeepRMSA**: Deep Reinforcement Learning for Routing and Spectrum Allocation  
   Chen et al., IEEE INFOCOM 2018

2. **MFDRL-RSA**: Multi-Feature Deep Reinforcement Learning for RSA  
   Natalino et al., Journal of Optical Communications 2020

3. **Optical RL-Gym**: Simulation Framework for RL in Optical Networks  
   https://github.com/carlosnatalino/optical-rl-gym

4. **Stable-Baselines3**: Reliable RL Implementations  
   https://stable-baselines3.readthedocs.io/

---

## ğŸ¨ Interfaz Visual

La demo usa **Rich library** para crear un dashboard profesional:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RMSA Live Comparison - Default vs Optimized        â”‚
â”‚            Episode 1 | Request #156 | 100â†’5 @ 200Gbps     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Default â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Optimized â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Blocking Probability:    15.38%       â”‚  â”‚ Blocking Probability:    3.85%      â”‚
â”‚ Acceptance Rate:         84.62%       â”‚  â”‚ Acceptance Rate:         96.15%     â”‚
â”‚ Spectral Utilization:    42.3%        â”‚  â”‚ Spectral Utilization:    68.7%      â”‚
â”‚ Fragmentation:           0.482        â”‚  â”‚ Fragmentation:           0.234      â”‚
â”‚ QoT Compliance:          0.846        â”‚  â”‚ QoT Compliance:          0.961      â”‚
â”‚ Reward:                  +12.4        â”‚  â”‚ Reward:                  +48.7      â”‚
â”‚ Last Action:             Path 2-5-9   â”‚  â”‚ Last Action:             Path 2-3-8 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Optimizaciones para CPU

El cÃ³digo incluye:
- âœ… Batch sizes optimizados para Ryzen 7 5700X3D
- âœ… Timesteps reducidos (30k/60k vs 50k/100k)
- âœ… Eval frequency balanceada
- âœ… Sin uso de GPU (compatible con AMD en Windows)
- âœ… Arquitecturas de red eficientes para CPU

---

## ğŸš€ PrÃ³ximos Pasos

1. **Ejecutar entrenamiento completo**: `python trainer.py --default --optimized`
2. **Lanzar demo visual**: `python demo.py`
3. **Analizar logs TensorBoard**: `tensorboard --logdir logs`
4. **Experimentar con hiperparÃ¡metros** en `config.py`
5. **Optimizar reward functions** para tu caso de uso

---

## ğŸ“ Notas TÃ©cnicas

- **PyTorch CPU** es ~3-5x mÃ¡s lento que GPU pero completamente funcional
- **Tiempos de entrenamiento** pueden variar segÃºn carga del sistema
- **Rich terminal** requiere terminal con soporte de color (PowerShell, Windows Terminal)
- **Modelos guardados** en formato `.zip` de Stable-Baselines3

---

## ğŸ¤ Contribuciones

Para mejorar esta demo:

1. Ajustar reward functions en `reward_functions.py`
2. AÃ±adir nuevas topologÃ­as en `rmsa_environment.py`
3. Mejorar visualizaciones en `visualizer.py`
4. Optimizar hiperparÃ¡metros con Optuna (ya incluido)

---

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Taller 3 Deep Reinforcement Learning

---

## ğŸ“ Autor

Desarrollado para demostraciÃ³n acadÃ©mica de Deep RL aplicado a redes Ã³pticas elÃ¡sticas.

**Hardware**: Ryzen 7 5700X3D + RX 6700XT + 16GB RAM  
**Stack**: Python 3.12 + PyTorch 2.5.1 + Gymnasium + SB3  
**Fecha**: Noviembre 2025

---

**Â¡Disfruta de la demo! ğŸ‰**
